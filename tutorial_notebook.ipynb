{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in ./tf-gpu-env/lib/python3.10/site-packages (0.3.4)\n",
      "Requirement already satisfied: packaging in ./tf-gpu-env/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: requests in ./tf-gpu-env/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./tf-gpu-env/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./tf-gpu-env/lib/python3.10/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./tf-gpu-env/lib/python3.10/site-packages (from requests->kagglehub) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./tf-gpu-env/lib/python3.10/site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./tf-gpu-env/lib/python3.10/site-packages (from requests->kagglehub) (2.2.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/mmckay/Desktop/Skill_Development/chest_xray_CNN_training/tf-gpu-env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "# work_dir = \"/Users/mmckay/Desktop/Skill_Development/chest_xray_CNN_training/DATA\"\n",
    "\n",
    "# print(work_dir, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "# def Build_CNN_Model():\n",
    "#     model = Sequential()\n",
    "#     # Add a 2D Convolutional layer with 32 filters and a 3x3 kernel\n",
    "#     model.add(Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 1)))\n",
    "#     # Remove all values that are negative and change to zero\n",
    "#     model.add(Activation('relu'))\n",
    "#     # Add a 2D MaxPooling layer with a 2x2 pool size(reduced function and take the maximum values in the pool)\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # Add a 2D Convolutional layer with 64 filters and a 3x3 kernel\n",
    "#     model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "#     # Remove all values that are negative and change to zero\n",
    "#     model.add(Activation('relu'))\n",
    "#     # Add a 2D MaxPooling layer with a 2x2 pool size(reduced function and take the maximum values in the pool)\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     # Add a 2D Convolutional layer with 128 filters and a 3x3 kernel\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "#     # Remove all values that are negative and change to zero\n",
    "#     model.add(Activation('relu'))\n",
    "#     # Add a 2D MaxPooling layer with a 2x2 pool size(reduced function and take the maximum values in the pool)\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     # -----------------------------------------------------\n",
    "#     # Apply flattening to the model - reduce from high deminsionallty to 1D(flat column)\n",
    "#     model.add(Flatten())\n",
    "#     # Add a dense layer with 1000 neurons\n",
    "#     model.add(Dense(1000))\n",
    "#     # Add a relu activation function to the dense layer\n",
    "#     model.add(Activation('relu'))\n",
    "#     # Add softmax activation function to the output layer for classification\n",
    "#     model.add(Dense(2))\n",
    "#     model.add(Activation('softmax'))\n",
    "#     # Display the model summary\n",
    "#     model.summary()\n",
    "\n",
    "#     # Compile the model with categorical crossentropy loss function and SGD optimizer\n",
    "#     opt = SGD(learning_rate=0.001)\n",
    "#     model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Build_CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 224, 224, 32)      320       \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 224, 224, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 112, 112, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 56, 56, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 56, 56, 128)       73856     \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 28, 28, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 100352)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              100353000 \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,447,674\n",
      "Trainable params: 100,447,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "def Build_CNN_Model():\n",
    "    model = Sequential()\n",
    "    # Add a 2D Convolutional layer with 32 filters and a 3x3 kernel\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 1)))\n",
    "    # Remove all values that are negative and change to zero\n",
    "    model.add(Activation('relu'))\n",
    "    # Add a 2D MaxPooling layer with a 2x2 pool size (reduced function and take the maximum values in the pool)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Add a 2D Convolutional layer with 64 filters and a 3x3 kernel\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    # Remove all values that are negative and change to zero\n",
    "    model.add(Activation('relu'))\n",
    "    # Add a 2D MaxPooling layer with a 2x2 pool size (reduced function and take the maximum values in the pool)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Add a 2D Convolutional layer with 128 filters and a 3x3 kernel\n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    # Remove all values that are negative and change to zero\n",
    "    model.add(Activation('relu'))\n",
    "    # Add a 2D MaxPooling layer with a 2x2 pool size (reduced function and take the maximum values in the pool)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Apply flattening to the model - reduce from high deminsionallty to 1D(flat column)\n",
    "    model.add(Flatten())\n",
    "    # Add a dense layer with 1000 neurons\n",
    "    model.add(Dense(1000))\n",
    "    # Add a relu activation function to the dense layer\n",
    "    model.add(Activation('relu'))\n",
    "    # Add softmax activation function to the output layer for classification\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Display the model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model with categorical crossentropy loss function and SGD optimizer\n",
    "    opt = SGD(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Example of using GPU\n",
    "if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = Build_CNN_Model()\n",
    "else:\n",
    "    print(\"No GPU available, building model on CPU\")\n",
    "    model = Build_CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_CNN_Model(model):\n",
    "    # Model Parameters\n",
    "    batch_size = 32\n",
    "    epochs = 100\n",
    "    # Data Augmentation fro grayscale xray images\n",
    "    # Data normalize by scaleing and shifting and normalizing the data\n",
    "    # - Scaling: making the pixel repersented as a float between 0 and 255 to a float between 0 and 1\n",
    "    # - Zero Mean Shifting: shifting the data to have a mean of 0\n",
    "    # - Normalization: scaling the data to have a standard deviation of 1 using the unit variance\n",
    "    # from keras.preprocessing.image import ImageDataGenerator\n",
    "    train_datagen =  ImageDataGenerator(rescale=1./255,featurewise_center=True, featurewise_std_normalization=True)\n",
    "    valid_datagen =  ImageDataGenerator(rescale=1./255,featurewise_center=True, featurewise_std_normalization=True)\n",
    "\n",
    "    # Load the training data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            '/Users/mmckay/Desktop/Skill_Development/chest_xray_CNN_training/DATA/train',\n",
    "            classes=['NORMAL', 'adnormal'],\n",
    "            target_size=(224, 224), \n",
    "            color_mode='grayscale',\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    # Load the validation data\n",
    "    valid_generator = valid_datagen.flow_from_directory(\n",
    "            '/Users/mmckay/Desktop/Skill_Development/chest_xray_CNN_training/DATA/val',\n",
    "            classes=['NORMAL', 'adnormal'],\n",
    "            target_size=(224, 224),\n",
    "            color_mode='grayscale',\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "    \n",
    "    history = model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=epochs, validation_data=valid_generator, validation_steps=len(valid_generator), verbose=1)\n",
    "\n",
    "    # Accuracy and Loss\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')  \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Save the model\n",
    "    model.save('chest_xray_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Build_CNN_Model()\n",
    "Train_CNN_Model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Add data from training to validation set to increase the size of the validation set - because overfitting is a major issue with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
